{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78d59da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== No RAG ===\n",
      "As of my last update in October 2023, there wasn't a widely recognized technology or concept known as \"OpenClaw.\" It's possible that it could refer to a niche project, an open-source software initiative, or a specific tool or library developed after my last update. \n",
      "\n",
      "If you could provide more context or specific details about what \"OpenClaw\" pertains to, I may be able to help you more effectively! Alternatively, you might want to check the latest online resources or news for the most current information.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langsmith import Client\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "no_rag_chain = llm | StrOutputParser()\n",
    "print(\"=== No RAG ===\")\n",
    "result1 = no_rag_chain.invoke(\"What is OpenClaw?\")\n",
    "print(result1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "491e079e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RAG ===\n",
      "Prompt: You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: {question} \n",
      "Context: {context} \n",
      "Answer:\n",
      "\n",
      "Question: Explain OpenClaw in detail.\n",
      "OpenClaw is a system designed specifically for Molty, an AI assistant modeled as a space lobster. However, the context does not provide detailed information about OpenClaw's features or functionalities. Therefore, I'm unable to provide further details.\n",
      "\n",
      "Question: How to install OpenClaw?\n",
      "To install OpenClaw, first clone the repository using the command `git clone https://github.com/openclaw/openclaw.git`, then navigate into the directory with `cd openclaw`.\n",
      "\n",
      "Question: How does OpenClaw work?\n",
      "OpenClaw is a personal AI assistant designed to operate on your own devices. Its functionality allows for personalized assistance while ensuring user privacy and control. The specifics of its operation are not detailed in the provided context.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loader = UnstructuredMarkdownLoader(\"./openclaw_info.md\")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20, add_start_index=True)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=all_splits,\n",
    "    embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    "    persist_directory=\"./chroma_embeddings\"\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "\n",
    "client = Client()\n",
    "prompt = client.pull_prompt(\"rlm/rag-prompt\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"\\n=== RAG ===\")\n",
    "print(\"Prompt: \" + prompt.messages[0].prompt.template + \"\\n\")\n",
    "questions = [\"Explain OpenClaw in detail.\", \"How to install OpenClaw?\", \"How does OpenClaw work?\"]\n",
    "for question in questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    result2 = rag_chain.invoke(question)\n",
    "    print(result2 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b89266ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Another RAG Prompt ===\n",
      "Prompt: You are an advanced assistant designed for question-answering and task execution using retrieved context. Use the provided pieces of context to accurately answer the question or perform the tasks requested by the user. If the context is insufficient, acknowledge it. Keep your responses concise and to the point.\n",
      "Context: {context}\n",
      "Question: {question}\n",
      "Answer:\n",
      "\n",
      "Question: Explain OpenClaw in detail.\n",
      "OpenClaw is an AI system specifically designed for Molty, who serves as a space lobster assistant. The context does not provide further details on its functionalities, capabilities, or design specifications beyond its purpose to assist Molty.\n",
      "\n",
      "Question: How to install OpenClaw?\n",
      "The provided context does not include specific installation instructions for OpenClaw beyond cloning the repository. To install it, you may need to refer to the project's documentation or README file in the cloned repository for detailed installation steps. You can also check for any dependencies or build instructions needed for the installation process.\n",
      "\n",
      "Question: How does OpenClaw work?\n",
      "The context does not provide specific details on how OpenClaw works. It is described as a personal AI assistant that runs on your own devices, but further information about its functionality, features, or operational mechanics is not available.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "another_prompt = client.pull_prompt(\"ahmedghani/agentic-rag\")\n",
    "another_rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | another_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print(\"\\n=== Another RAG Prompt ===\")\n",
    "print(\"Prompt: \" + another_prompt.messages[0].prompt.template + \"\\n\")\n",
    "for question in questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    result3 = another_rag_chain.invoke(question)\n",
    "    print(result3+ \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
